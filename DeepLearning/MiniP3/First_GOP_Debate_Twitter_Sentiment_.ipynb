{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First GOP Debate Twitter Sentiment .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTGI8l4mglIp"
      },
      "source": [
        "#Prepare Dataset\n",
        "\n",
        "This data originally came from Crowdflower's Data for Everyone library.\n",
        "\n",
        "As the original source says,\n",
        "\n",
        ">We looked through tens of thousands of tweets about the early August GOP debate in Ohio and asked contributors to do both sentiment analysis and data categorization. Contributors were asked if the tweet was relevant, which candidate was mentioned, what subject was mentioned, and then what the sentiment was for a given tweet. We've removed the non-relevant messages from the uploaded dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ0l9HTkc8C4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG_FHZpPdg03"
      },
      "source": [
        "read the data using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "aNUEtYhHdhgL",
        "outputId": "8da57693-99d1-4578-88a7-cff3d598d05e"
      },
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "data.head(20)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@JGreenDC @realDonaldTrump In all fairness #Bi...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @WayneDupreeShow: Just woke up to tweet thi...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Me reading my family's comments about how grea...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RT @ArcticFox2016: RT @AllenWestRepub \"Dear @J...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RT @pattonoswalt: I loved Scott Walker as Mark...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Hey @ChrisChristie exploiting the tragedy of 9...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RT @CarolCNN: #DonaldTrump under fire for comm...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RT @johncardillo: Guess who had most speaking ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>reason comment is funny 'in case you're ignora...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RT @PamelaGeller: Huckabee: Paying for transge...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text sentiment\n",
              "0   RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
              "1   RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
              "2   RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
              "3   RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
              "4   RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
              "5   RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
              "6   RT @warriorwoman91: I liked her and was happy ...  Negative\n",
              "7   Going on #MSNBC Live with @ThomasARoberts arou...   Neutral\n",
              "8   Deer in the headlights RT @lizzwinstead: Ben C...  Negative\n",
              "9   RT @NancyOsborne180: Last night's debate prove...  Negative\n",
              "10  @JGreenDC @realDonaldTrump In all fairness #Bi...  Negative\n",
              "11  RT @WayneDupreeShow: Just woke up to tweet thi...  Positive\n",
              "12  Me reading my family's comments about how grea...  Negative\n",
              "13  RT @ArcticFox2016: RT @AllenWestRepub \"Dear @J...   Neutral\n",
              "14  RT @pattonoswalt: I loved Scott Walker as Mark...  Positive\n",
              "15  Hey @ChrisChristie exploiting the tragedy of 9...  Negative\n",
              "16  RT @CarolCNN: #DonaldTrump under fire for comm...  Negative\n",
              "17  RT @johncardillo: Guess who had most speaking ...  Negative\n",
              "18  reason comment is funny 'in case you're ignora...  Negative\n",
              "19  RT @PamelaGeller: Huckabee: Paying for transge...  Negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSHZAOP4dxFI"
      },
      "source": [
        "We will create a function to remove unwanted characters in Tweets using Regex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "MXNiukD_dtkT",
        "outputId": "98ace57e-1424-4e5a-8b23-d0ea03dde339"
      },
      "source": [
        "def preProcess_data(text):\n",
        "   text = text.lower()\n",
        "   new_text = re.sub('[^a-zA-z0-9\\s]','',text)\n",
        "   new_text = re.sub('rt', '', new_text)\n",
        "   return new_text\n",
        "\n",
        "data['text'] = data['text'].apply(preProcess_data)\n",
        "data.head(20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nancyleegrahn how did everyone feel about the...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>scottwalker didnt catch the full gopdebate la...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tjmshow no mention of tamir rice and the gopd...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>robgeorge that carly fiorina is trending  hou...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>danscavino gopdebate w realdonaldtrump delive...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gregabbott_tx tedcruz on my first day i will ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>warriorwoman91 i liked her and was happy when...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>going on msnbc live with thomasarobes around 2...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>deer in the headlights  lizzwinstead ben carso...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>nancyosborne180 last nights debate proved it ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>jgreendc realdonaldtrump in all fairness billc...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>waynedupreeshow just woke up to tweet this ou...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>me reading my familys comments about how great...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>arcticfox2016  allenwestrepub dear jebbush go...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>pattonoswalt i loved scott walker as mark har...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hey chrischristie exploiting the tragedy of 91...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>carolcnn donaldtrump under fire for comments ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>johncardillo guess who had most speaking time...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>reason comment is funny in case youre ignorant...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>pamelageller huckabee paying for transgender ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text sentiment\n",
              "0    nancyleegrahn how did everyone feel about the...   Neutral\n",
              "1    scottwalker didnt catch the full gopdebate la...  Positive\n",
              "2    tjmshow no mention of tamir rice and the gopd...   Neutral\n",
              "3    robgeorge that carly fiorina is trending  hou...  Positive\n",
              "4    danscavino gopdebate w realdonaldtrump delive...  Positive\n",
              "5    gregabbott_tx tedcruz on my first day i will ...  Positive\n",
              "6    warriorwoman91 i liked her and was happy when...  Negative\n",
              "7   going on msnbc live with thomasarobes around 2...   Neutral\n",
              "8   deer in the headlights  lizzwinstead ben carso...  Negative\n",
              "9    nancyosborne180 last nights debate proved it ...  Negative\n",
              "10  jgreendc realdonaldtrump in all fairness billc...  Negative\n",
              "11   waynedupreeshow just woke up to tweet this ou...  Positive\n",
              "12  me reading my familys comments about how great...  Negative\n",
              "13   arcticfox2016  allenwestrepub dear jebbush go...   Neutral\n",
              "14   pattonoswalt i loved scott walker as mark har...  Positive\n",
              "15  hey chrischristie exploiting the tragedy of 91...  Negative\n",
              "16   carolcnn donaldtrump under fire for comments ...  Negative\n",
              "17   johncardillo guess who had most speaking time...  Negative\n",
              "18  reason comment is funny in case youre ignorant...  Negative\n",
              "19   pamelageller huckabee paying for transgender ...  Negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oDl4Yz8eLZu"
      },
      "source": [
        "We will use Tensorflow’s tokenizer to tokenize our dataset, and Tensorflow’s pad_sequences to pad our sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r0xoMXDdzRg",
        "outputId": "f7a30099-5dd5-4724-a0b0-0d04ccf7c3e5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_fatures = 2000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X, 32) \n",
        "\n",
        "Y = pd.get_dummies(data['sentiment']).values\n",
        "for i in range(3):\n",
        "  print(data['text'][i])\n",
        "  print(data['sentiment'][i])\n",
        "  print(Y[i])\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " nancyleegrahn how did everyone feel about the climate change question last night exactly gopdebate\n",
            "Neutral\n",
            "[0 1 0]\n",
            " scottwalker didnt catch the full gopdebate last night here are some of scotts best lines in 90 seconds walker16 httptcozsff\n",
            "Positive\n",
            "[0 0 1]\n",
            " tjmshow no mention of tamir rice and the gopdebate was held in cleveland wow\n",
            "Neutral\n",
            "[0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U25M9CPceXeT"
      },
      "source": [
        "split the dataset into training and testing portions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCsdtPhpeHVb",
        "outputId": "d2cf72eb-9e56-48fe-ad72-3faab5728463"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20)\n",
        "print(len(X_train), \"Training sequences\")\n",
        "print(len(X_test), \"Validation sequences\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11096 Training sequences\n",
            "2775 Validation sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOPTqsFFgQ1l"
      },
      "source": [
        "#LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LBtiCdEefza"
      },
      "source": [
        "We will simply use an embedding layer and some LSTM layers with dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYYcT4-ceYvf",
        "outputId": "7524c72f-0eed-49d5-fa92-d837714909b7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(128,recurrent_dropout=0.2))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 32, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 32, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32, 196)           254800    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               166400    \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 677,587\n",
            "Trainable params: 677,587\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDx5-mYeiBD",
        "outputId": "935d59a3-0c3d-43b0-8a6a-a8764685069c"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 16s 270ms/step - loss: 0.9096 - accuracy: 0.6115 - val_loss: 0.8239 - val_accuracy: 0.6238\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 11s 254ms/step - loss: 0.7649 - accuracy: 0.6654 - val_loss: 0.7382 - val_accuracy: 0.6757\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 11s 259ms/step - loss: 0.6867 - accuracy: 0.7023 - val_loss: 0.7262 - val_accuracy: 0.6868\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 12s 266ms/step - loss: 0.6427 - accuracy: 0.7254 - val_loss: 0.7200 - val_accuracy: 0.6829\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 12s 261ms/step - loss: 0.6194 - accuracy: 0.7386 - val_loss: 0.7239 - val_accuracy: 0.6825\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 11s 260ms/step - loss: 0.5982 - accuracy: 0.7476 - val_loss: 0.7455 - val_accuracy: 0.6811\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 11s 260ms/step - loss: 0.5800 - accuracy: 0.7508 - val_loss: 0.7561 - val_accuracy: 0.6905\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 11s 255ms/step - loss: 0.5626 - accuracy: 0.7626 - val_loss: 0.7559 - val_accuracy: 0.6847\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 12s 266ms/step - loss: 0.5511 - accuracy: 0.7676 - val_loss: 0.7489 - val_accuracy: 0.6775\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 12s 262ms/step - loss: 0.5386 - accuracy: 0.7760 - val_loss: 0.7747 - val_accuracy: 0.6746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd7f22cef10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJn300dDFDtz",
        "outputId": "3aac979d-21f9-4cfa-ba8b-52578d8fc23e"
      },
      "source": [
        "txt = 'pattonoswalt i hate scott walker'\n",
        "true_label = 'Neg'\n",
        "labels =['Negaive' ,'Neutral','Positive']\n",
        "seq = tokenizer.texts_to_sequences([txt])\n",
        "padded = pad_sequences(seq, 32)\n",
        "\n",
        "pred = model.predict(padded)\n",
        "print(ex,pred)\n",
        "print('\\n',labels,'\\n',pred)\n",
        " "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pattonoswalt i loved scott walker [[0.8655635  0.12268818 0.0117483 ]]\n",
            "\n",
            " ['Negaive', 'Neutral', 'Positive'] \n",
            " [[0.8655635  0.12268818 0.0117483 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mAmaasqFvre"
      },
      "source": [
        "**We can see that the model preditcs our phrase correctly! :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhoHB74LgVZS"
      },
      "source": [
        "#Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCs4T9sqgaFu"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAbPAYlvhP5E"
      },
      "source": [
        "Implement a Transformer block as a layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlDNeo2UhNgW"
      },
      "source": [
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqKlD8LkhXvY"
      },
      "source": [
        "Implement embedding layer\n",
        ">Two seperate embedding layers, one for tokens, one for token index (positions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjxbRHe0hOy_"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M28J2GMmh2tD"
      },
      "source": [
        "Create classifier model using transformer layer\n",
        ">Transformer layer outputs one vector for each time step of our input sequence. Here, we take the mean across all time steps and use a feed forward network on top of it to classify text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3iMPf7hhg35",
        "outputId": "d7e66b92-d35e-457a-c6a1-bee2b6e1daa9"
      },
      "source": [
        "embed_dim = 64  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "\n",
        "\n",
        "inputs = layers.Input(X.shape[1])\n",
        "embedding_layer = TokenAndPositionEmbedding(32, max_fatures, embed_dim)\n",
        "\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "token_and_position_embedding (None, 32, 64)            130048    \n",
            "_________________________________________________________________\n",
            "transformer_block_10 (Transf (None, 32, 64)            41792     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 173,203\n",
            "Trainable params: 173,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGt3cZmxiCw3",
        "outputId": "3fe886c0-28f6-4d55-acb1-5980e74588a8"
      },
      "source": [
        "batch_size=128\n",
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test, Y_test)\n",
        ")\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "87/87 [==============================] - 2s 13ms/step - loss: 0.9229 - accuracy: 0.6019 - val_loss: 0.8280 - val_accuracy: 0.6014\n",
            "Epoch 2/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7951 - accuracy: 0.6371 - val_loss: 0.7459 - val_accuracy: 0.6724\n",
            "Epoch 3/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7101 - accuracy: 0.6921 - val_loss: 0.7279 - val_accuracy: 0.6677\n",
            "Epoch 4/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6504 - accuracy: 0.7233 - val_loss: 0.7719 - val_accuracy: 0.6735\n",
            "Epoch 5/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6302 - accuracy: 0.7331 - val_loss: 0.7405 - val_accuracy: 0.6879\n",
            "Epoch 6/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5908 - accuracy: 0.7467 - val_loss: 0.7757 - val_accuracy: 0.6764\n",
            "Epoch 7/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5733 - accuracy: 0.7523 - val_loss: 0.8060 - val_accuracy: 0.6829\n",
            "Epoch 8/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5536 - accuracy: 0.7586 - val_loss: 0.8204 - val_accuracy: 0.6879\n",
            "Epoch 9/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5343 - accuracy: 0.7720 - val_loss: 0.8275 - val_accuracy: 0.6786\n",
            "Epoch 10/10\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5269 - accuracy: 0.7771 - val_loss: 0.8524 - val_accuracy: 0.6706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86b1k_-r6aXV",
        "outputId": "6a5d12c7-d72e-4f8d-91c5-f0ca0ae91f94"
      },
      "source": [
        "txt = 'pattonoswalt i do no know but hate scott walker'\n",
        "true_label = 'Neg'\n",
        "labels =['Negaive' ,'Neutral','Positive']\n",
        "seq = tokenizer.texts_to_sequences([txt])\n",
        "padded = pad_sequences(seq, 32)\n",
        "\n",
        "pred = model.predict(padded)\n",
        "print(ex,pred)\n",
        "print('\\n',labels,'\\n',pred)\n",
        " "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pattonoswalt i loved scott walker [[0.83604825 0.1623583  0.00159346]]\n",
            "\n",
            " ['Negaive', 'Neutral', 'Positive'] \n",
            " [[0.83604825 0.1623583  0.00159346]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUKSZUicGc_-"
      },
      "source": [
        "**We can see that also this model preditcs our phrase correctly! :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kto6aOm0zMV6"
      },
      "source": [
        "#Conclusion:\n",
        "\n",
        ">We can see that the trasnformer was very fast in training.\n",
        "\n",
        ">Also trasnformer with much less parameters achieved the same val_accuracy "
      ]
    }
  ]
}